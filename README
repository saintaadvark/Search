Searching...

Mon DEc 26: O(n) substring search, refactoring, commenting, all that cool stuff codes do from time to time.
Entire dictionary doesnt OOM, yay! on second though the reason for this is obvious, acronym definitions have the same string repeated = wasted bytes. dictionaries
dont. Also, added substring search to disksearch.c, original naive plan was to:
1. grab a dictionary word, add it to tree
2. search through definitions of acronyms for that word
3. if found add acronym to dictionary words node.
This is way too slow, and will continue to be so even if multi threaded. There are too many dictionary words like antiquated and microorganism that just dont show 
up in the acronym list, doing a complete substring search for them is a cpu hog. New plan is:
1. Go through list of acronyms definitions
2. compare each word to list of filler words so we dont waste our time on this and that, or rather, "this" and "that". 
3. for each valuable word found in a definition, fire off a thread to update word's tree node, all words differ so they wont compete.
	An alternate approach would be to fire off 26 different threads to work on each section of the acronym file
	but we would avoid contention if we started threads on words=nodes that we know are different.
4. So now we have a RBT of dictionary words, each with its list of acronyms, each with their list of dictionary words (from their definitons). This forms a graph.
	eg: FTASB = faster than a speeding bullet
	    speeding has FTASB, FTASB has bullet
	    search speeding and get FTASB and, say, BT (bullet time)
ToDo:
disksearch.c: Handle 'ing' case. speed needs results from speeding too. 
threadPool.c: threadpool kill, free memory
graph.c: restructure to build tree 'on demand' per node instead of loading entire dictionary
tree.c: implement delete on RBT, implement splay tree

Sun Dec 25: Merry Christmas.
Added 'disksearch.c'. Stepwise:
1. create a thread pool.
1. thread '1' scans file and notes offset in bytes for each alphabet range in a lookup table.
2. each string of input is posted as a future. threads grab future according to availability and execute search function.
3. search function checks byte offset for acronym string[0], and performs a binary search within range of that alphabet, for the acronym. Binary search terminates 
	either when the word is found or when search has been narrowed down to size DISKBLOCK, on the expectation that a linear search within DISKBLOCK will be cheap 
	since it's probably already in L1/L2 cache. 	
This approach seems fast enough, and scalable. Caveats noted in comments in disksearch.c.

No additional code has gone into the tree cache, but from a design perspective, if the entire english dictionary (just the words) will fit in RAM we've lucked out. 
1. Everytime someone types in a word, say 'Live', send a thread through the acronym list looking for all acronyms with the word 'Live' in it's meaning. 
2. Create a node for 'Live' and add to it a list of acronyms that have 'Live' in their definition. Cache this in a RBT or a splay tree.
3. The second time someone asks for live we have the list of acronyms and all we need to do is fork multiple threads to find each acronym in the file. 
The first time will unfortunately be slow unless the dictionsry tree will fit before hand.

Not sure how this will change with the recommendations concept. This will achieve only the first half of search (i.e related results of input). To achieve 
recommendations the acronyms themselves will need nodes in the graph. Memory is fast becoming dear.


Sat Dec24: More verbose commit comments starting today.
Tree is obviously biased if we add keys alphabetically. Need a data structure that can manage memory and time efficiently and is open to multi threaded perf, whatever 
it is, it's going to need to rotate. 'it' will probably be an RBT.

1. Add parent pointers to tree. 
2. Implement rotation left and right.

Implemented RBT but run out of memory at about 1000 acronyms and their defs. Possible solutions include:
1. add 20 acronyms per node: modify searcher to stop at start/end range and perform binary search within array.
2. maintain most popular acronyms in tree and just lookup others in file. 
	How would we find most popular?
	Need to Implement delete for this.
	splay tree?
	
3. add 20/node but only when we hit 800. That way by then each word might have 20 search connections and we can add related nodes in the same group.
	Search becomes a problem unless we maintain a subsidiary array for the acronyms. This appproach seems sucky, but FWIW.
4. threads wont alleviate the problem but processes might as we can reply on os to write to disk. let each process deal w/ an alphabet and report back. We'd need to 
	use pipes and stuff to communicate though =(


